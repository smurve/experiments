{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principles and Patterns for ML Practitioners\n",
    "\n",
    "### S.O.L.I.D (and more) principles applied to an ML problem\n",
    "\n",
    "##### By Wolfgang Giersche, ZÃ¼hlke Engineering AG\n",
    "\n",
    "![solid gold](images/solid_gold.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principles and Practices in Code\n",
    "\n",
    "#### - Motivation: Typical Python ML code\n",
    "#### - SWE's S.O.L.I.D Principles\n",
    "#### - Background: Machine Learning with Tensorflow\n",
    "#### - Tutorial: Structured Experiments in Python\n",
    "\n",
    "# Principles and Practices in Collaboration\n",
    "\n",
    "#### - Explore - Experiment - Build - Infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "[The official Tensorflow MNIST example](mnist_original.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# There's More to Code Than Coding\n",
    "\n",
    "## Minimize learning curve for those after you\n",
    "## Code is written once, read and changed multiple times\n",
    "## Dare touch a running system: make it easy-to-change\n",
    "## Reduce efforts for testing\n",
    "## Minimize dependency and reduce complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exactly because data analytics and machine learning\n",
    "\n",
    "## have rather *exploratory traits*\n",
    "\n",
    "## practices should better support *code and config changes* \n",
    "\n",
    "## *without endangering* the quality of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Anatomy of a Machine Learning Experiment\n",
    "![Anatomy of an ML epic](images/Anatomy-of-an-experiment.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Principles to the Rescue: S.O.L.I.D\n",
    "The [S.O.L.I.D. Principles](http://www.cvc.uab.es/shared/teach/a21291/temes/object_oriented_design/materials_adicionals/principles_and_patterns.pdf) \n",
    "are commonly attributed to [Robert C. Martin (Uncle Bob)](https://de.wikipedia.org/wiki/Robert_Cecil_Martin).\n",
    "\n",
    "### SRP = Single Responsibility Principle\n",
    "### OCP = Open-Close Principle\n",
    "### LSP = Liskov Substitution Principle\n",
    "### ISP = Interface Segregation Principle\n",
    "### DIP = Dependency Inversion Principle\n",
    "#### ...and following those principles leads to patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Background: Tensorflow\n",
    "\n",
    "### Tensorflow already sports an extremely helpful design\n",
    "\n",
    "### The actual processing is described by a computational graph\n",
    "\n",
    "### ```Dataset```s, ```Estimator```s, and ```Tower```s manage the training for you\n",
    "\n",
    "\n",
    "The content here is heavily inspired by the \n",
    "[github tensorflow repo](https://github.com/tensorflow/models/tree/master/official/mnist) - \n",
    "indeed initially copied, and then significantly refactored to demonstrate how SWE patterns and principles make the code more readable, testable and reusable.\n",
    "\n",
    "We're using [Zalando Research's Fashion Dataset](https://github.com/zalandoresearch/fashion-mnist)\n",
    "in addition to the well-known [Handwritten Digits](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The pipeline | the neural network\n",
    "- | - \n",
    "![alt](images/ds-pipeline.png) | ![alt](images/nn-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensorflow Building Blocks\n",
    "##### I am using the most current TF API 1.8.0 with the following building blocks:\n",
    "\n",
    "- [Tensorflow Dataset API](https://www.tensorflow.org/programmers_guide/datasets)\n",
    "    - Allows for pre-processing with a monadic API (map, flatmap, etc)\n",
    "    - Preprocessing may even happen in parallel streaming fashion\n",
    "    \n",
    "- [Estimator API](https://www.tensorflow.org/programmers_guide/estimators)\n",
    "    - very convenient highlevel API\n",
    "    - Checkpointing and recovery \n",
    "    - Tensorboard summaries\n",
    "    - much more...    \n",
    "    \n",
    "- [Multi-GPU Training of contrib.estimator package](https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/)\n",
    "    - convenient wrapper to distribute training on any number of GPUs on a single machine\n",
    "    - works by means of synchonous gradient averaging over parallel mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The ```Dataset``` API\n",
    "\n",
    "``` python\n",
    "def train_input_fn():\n",
    "    ds_tr = dataset.training_dataset(hparams.data_dir, DATA_SET)\n",
    "    ds_tr_tr, _ = split_datasource(ds_tr, 60000, 0.95)\n",
    "    ds1 = ds_tr_tr.cache().shuffle(buffer_size=57000).\\\n",
    "        repeat(hparams.train_epochs).\\\n",
    "        batch(hparams.batch_size)\n",
    "    return ds1\n",
    "\n",
    "def eval_input_fn():\n",
    "    ds_tr = dataset.training_dataset(hparams.data_dir, DATA_SET)\n",
    "    _, ds_tr_ev = split_datasource(ds_tr, 60000, 0.95)\n",
    "    ds2 = ds_tr_ev.batch(hparams.batch_size)\n",
    "    return ds2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The ```Estimator``` API\n",
    "Create an ```Estimator``` by passing a *model function* to the constructor\n",
    "\n",
    "``` python\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_function,\n",
    "    model_dir=hparams.model_dir,\n",
    "    params={\n",
    "        'data_format': data_format,\n",
    "        'multi_gpu': hparams.multi_gpu\n",
    "    })\n",
    "```\n",
    "\n",
    "The model function must return appropriate ```EstimatorSpec```s for 'TRAIN', 'EVAL', or 'TEST'. We create it in its own module using a given ```Model```.\n",
    "\n",
    "A ```Model``` is the function that actually creates the graph. Two possible implementations can be found in their own modules in the ```models``` package \n",
    "\n",
    "``` python\n",
    "model_function = create_model_fn(\n",
    "    lambda params: Model(params),\n",
    "    tf.train.AdamOptimizer(),\n",
    "    tf.losses.sparse_softmax_cross_entropy,\n",
    "    hparams)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train\n",
    "``` python\n",
    "start_time=time.time()\n",
    "mnist_classifier.train(input_fn=train_input_fn, hooks=[logging_hook])\n",
    "duration=time.time() - start_time\n",
    "```\n",
    "\n",
    "## Evaluate\n",
    "``` python\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "accuracy = eval_results['accuracy']\n",
    "steps = eval_results['global_step']\n",
    "duration = int(duration)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "[run_experiment.ipynb](run_experiment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explore - Experiment - Train - Inference\n",
    "![ex-ex-tr-inf](images/Ex-Ex-Tr-Inf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supplementary material in this tutorial:\n",
    "\n",
    "- parallel training on two or more GPUs\n",
    "- The concept of Estimator and EstimatorSpec\n",
    "- Datasets and functional monadic interfaces\n",
    "- The concept of a computational graph -> tf.InteractiveSession() to the rescue\n",
    "- Neural networks: concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
